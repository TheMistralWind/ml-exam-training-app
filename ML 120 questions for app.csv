Question ID,Question,Option A,Option B,Option C (Correct),Option D,Correct Answer,Topic
Q1,Which of the following best describes the task of Supervised Learning?,The goal is to find groups of similar data points without any prior labels.,The agent learns to act in an environment to maximize its cumulative future reward.,"The model learns a mapping from an input x to an output y using a dataset of labeled input-output pairs (xi​,yi​).",The system learns an internal representation of the input data for dimensionality reduction.,C,Introduction & Basics
Q2,"In a typical data matrix D, how are the observations (data points) and features usually arranged?","Features are rows, Observations are columns.","Observations are rows, Features are columns.","Observations are rows, Features are columns.",The arrangement depends on the kernel function used.,B,Introduction & Basics
Q3,What is the primary purpose of the convolution operation as a feature extractor in image processing?,To linearly separate classes in the input space.,To transform the input data into a high-dimensional feature space.,"To compute a linear combination of a pixel’s neighbors, often for feature extraction or smoothing.",To estimate the probability density function of the image pixels.,C,Introduction & Basics
Q4,"Which machine learning paradigm is characterized by an agent, a reward signal, and a sequence of actions and states?",Unsupervised Learning,Supervised Learning,Reinforcement Learning,Transductive Learning,D,Introduction & Basics
Q5,The Quadratic Loss (Squared Error) function is the standard choice for optimizing the parameters in which model?,Logistic Regression,Linear Regression (Least Squares Estimation),Linear Regression (Least Squares Estimation),Support Vector Machines (SVM),B,Regression & Loss
Q6,What is the key principle that guides the training of a Support Vector Machine (SVM) classifier?,Minimizing the total number of misclassified points.,Maximizing the margin between the decision boundary and the closest data points (support vectors).,Maximizing the margin between the decision boundary and the closest data points (support vectors).,Finding the minimum of the maximum likelihood function.,B,Regression & Loss
Q7,"The Hinge Loss function, which penalizes predictions that are not confidently correct, is predominantly used for training which classifier?",Logistic Regression,Linear Regression,Support Vector Machines (SVM),Decision Trees,D,Regression & Loss
Q8,"In a binary classification problem, which term in the Confusion Matrix represents the number of positive instances that were incorrectly predicted as negative?",False Positives (FP),True Negatives (TN),False Negatives (FN),True Positives (TP),C,Classification & Metrics
Q9,Which single metric is calculated as the harmonic mean of Precision and Recall?,Accuracy,F-score (F1​ or Fβ​),F-score (F1​ or Fβ​),Brier Score,B,Classification & Metrics
Q10,The Receiver Operating Characteristic (ROC) curve visually compares the trade-off between which two classification metrics?,Precision and Recall,F-score and Accuracy,True Positive Rate (Sensitivity) and False Positive Rate (1 - Specificity),Bias and Variance,C,Classification & Metrics
Q11,What is the fundamental role of the sigmoid activation function in Logistic Regression?,To introduce non-linearity for solving non-linear problems.,To project the output of the linear model into a probability value between 0 and 1.,To project the output of the linear model into a probability value between 0 and 1.,To prevent overfitting by regularizing the weights.,B,Classification & Metrics
Q12,"What problem is regularization (e.g., L1 or L2) primarily designed to mitigate in regression models?",Underfitting,Computational complexity,Overfitting,Non-linear separability,C,Classification & Metrics
Q13,The main objective of Principal Component Analysis (PCA) is:,To select a subset of the most relevant features (feature selection).,To transform the data to a new set of orthogonal coordinates that maximize the data's variance (dimensionality reduction).,To transform the data to a new set of orthogonal coordinates that maximize the data's variance (dimensionality reduction).,To normalize the features to have zero mean and unit variance.,B,Feature Learning & PCA
Q14,What is the primary benefit of the Kernel Trick used in algorithms like the Kernel SVM?,It allows for the use of the L2 regularization norm.,It enables non-linear classification by implicitly computing dot products in a high-dimensional feature space.,It enables non-linear classification by implicitly computing dot products in a high-dimensional feature space.,It reduces the number of dimensions required for the training data.,B,Feature Learning & PCA
Q15,The k-Nearest Neighbor (k-NN) algorithm is a classic example of which type of machine learning method?,Parametric method,Instance-based learning (or memory-based learning),Instance-based learning (or memory-based learning),Generative model,B,Non-Parametric & Ensemble
Q16,"In the context of Decision Trees, which concept is used to quantify the impurity of a node, with the goal of minimizing it to find the best split?",Maximum Likelihood Estimate (MLE),Brier Score,Information Gain (or Gini Impurity),Maximum Margin Principle,C,Non-Parametric & Ensemble
Q17,What distinguishes Random Forests from standard Tree Bagging?,"Random Forests use the Gini impurity, while Bagging uses Information Gain.","Random Forests only use L1 regularization, while Bagging uses L2.","Random Forests introduce a random subset of features at each split, in addition to using a random subset of data.","Random Forests build trees sequentially, whereas Bagging builds them in parallel.",C,Non-Parametric & Ensemble
Q18,What is the fundamental assumption made by the Parzen Estimator method for probability density estimation?,The distribution is assumed to be Gaussian.,The probability mass P is approximately equal to the density P(x) multiplied by the volume V of a small region R around x.,The probability mass P is approximately equal to the density P(x) multiplied by the volume V of a small region R around x.,The estimation is non-parametric and requires infinite data.,B,Non-Parametric & Ensemble
Q19,"What is the general term for the process of manually creating new, more informative input features from the existing raw data using domain knowledge?",Feature Selection,Feature Scaling,Feature Engineering,Feature Normalization,C,Feature Learning & PCA
Q20,"In the context of ensemble methods, Bagging (Bootstrap Aggregating) primarily helps to reduce which characteristic of the model?",Bias,Variance,Variance,Computational time,B,Non-Parametric & Ensemble
Q21,The K-means algorithm is a partition-based clustering method that aims to minimize which common objective function?,The distance between the closest clusters.,The maximum distance between any two points in the data.,The sum of the distances between each point and its assigned cluster centroid (WCSS).,The number of core points.,C,Clustering
Q22,"Which clustering algorithm is advantageous for identifying clusters of arbitrary, non-spherical shapes and explicitly labeling outliers as ""noise""?",K-means,Gaussian Mixture Models,DBSCAN (Density-Based Spatial Clustering of Applications with Noise),Hierarchical Clustering,D,Clustering
Q23,"In the context of Probability Theory, what is the goal of the Maximum Likelihood Estimation (MLE) method?",To maximize the prior probability of the parameters.,To find the parameter values that maximize the probability (or likelihood) of observing the given data.,To find the parameter values that maximize the probability (or likelihood) of observing the given data.,To minimize the posterior probability.,B,Probability & Estimation
Q24,Bayesian Estimation uses the Bayes' rule to combine the data's likelihood with what to produce a posterior estimate of the parameters?,The Maximum Likelihood Estimate (MLE),The prior distribution of the parameters,The prior distribution of the parameters,The Aleatoric Uncertainty,B,Probability & Estimation
Q25,Which type of uncertainty in machine learning predictions is caused by the inherent randomness or noise in the system being measured and cannot be reduced by increasing the training data size?,Epistemic Uncertainty,Model Uncertainty,Aleatoric Uncertainty,Structural Uncertainty,C,Probability & Estimation
Q26,The Binomial distribution is defined as the probability distribution of what?,The number of successes in a fixed number of independent Bernoulli trials.,The time until the next event in a Poisson process.,The number of successes in a fixed number of independent Bernoulli trials.,The likelihood of a continuous random variable.,A,Probability & Estimation
Q27,"When applying clustering to a dataset with no predefined labels, what general type of learning is being performed?",Supervised Learning,Reinforcement Learning,Unsupervised Learning,Semi-supervised Learning,D,Clustering
Q28,"An MLE estimate for the mean (μ) of a Gaussian distribution, assuming known variance, is simply the:",Median of the observed data.,Mode of the observed data.,Arithmetic mean (sample mean) of the observed data.,Square root of the variance.,C,Probability & Estimation
Q29,What is the fundamental dilemma in Reinforcement Learning and Multi-armed Bandit problems that the agent must constantly balance?,Bias vs. Variance,Gradient vs. Loss,Exploration (trying new actions) vs. Exploitation (using the best-known action),Batch vs. Online Learning,C,RL & Bandits
Q30,What is the key difference between a Multi-armed Bandit problem and a Contextual Bandit problem?,Contextual Bandits allow the agent to receive a reward delayed over time.,"Multi-armed Bandits are for continuous action spaces, while Contextual Bandits are for discrete action spaces.","Contextual Bandits use a feature vector (context) to guide action selection, whereas Multi-armed Bandits only have a single state.","Multi-armed Bandits seek to maximize long-term reward, while Contextual Bandits seek immediate reward.",C,RL & Bandits
Q31,The Upper Confidence Bound (UCB) algorithm encourages exploration by selecting an arm based on its estimated average reward plus a bonus term that is proportional to its:,Known high variance.,Number of times it has been pulled (or time since last pull).,Number of times it has been pulled (or time since last pull).,Negative reward.,B,RL & Bandits
Q32,"In the training of an Artificial Neural Network (ANN), what is the function of the Backpropagation algorithm?",To compute the forward pass of the input through the network.,To calculate the gradient of the loss function with respect to the network weights.,To calculate the gradient of the loss function with respect to the network weights.,To randomly initialize the weights and biases.,B,Deep Learning
Q33,Which architectural component in a Convolutional Neural Network (CNN) is primarily responsible for learning hierarchical spatial features from input data like images?,The Fully Connected Layer,The Pooling Layer,The Convolutional Layer,The Softmax Layer,C,Deep Learning
Q34,Recurrent Neural Networks (RNNs) are uniquely suited for sequential data due to what characteristic?,They use only linear activation functions.,They maintain an internal hidden state which passes information from one step in the sequence to the next.,They maintain an internal hidden state which passes information from one step in the sequence to the next.,They use only the Attention mechanism.,B,Deep Learning
Q35,The introduction of Long Short-Term Memory (LSTM) networks primarily addressed which major issue in traditional RNNs?,Overfitting on small datasets.,The vanishing or exploding gradient problem over long sequences.,The vanishing or exploding gradient problem over long sequences.,Inability to process text data.,B,Deep Learning
Q36,"What is the primary purpose of the Pooling Layer (e.g., max pooling) in a CNN?",To increase the number of parameters.,To calculate the error gradient.,"To reduce the spatial size of the feature map, making the model more robust to position shifts.",To introduce non-linearity into the model.,C,Deep Learning
Q37,Which Natural Language Processing (NLP) model is an example of a semantic model that learns word embeddings by predicting context words from a target word (or vice versa)?,DBSCAN,Word2Vec,Word2Vec,Random Forest,B,LLMs & NLP
Q38,The defining mechanism that allows Transformer models to selectively focus on and weigh the importance of different parts of the input sequence when processing a specific element is called the:,Backpropagation mechanism,Convolutional kernel,Attention mechanism,Gated Recurrent Unit (GRU),D,LLMs & NLP
Q39,What are Large Language Models (LLMs) fundamentally trained to do?,To minimize the Brier score on a fixed dataset.,To predict the next word or token in a sequence.,To predict the next word or token in a sequence.,To perfectly classify images based on visual features.,B,LLMs & NLP
Q40,Natural Language Processing (NLP) is defined as the computerized processing of which type of data?,Structured numerical data,Image data,Natural language (text or speech),Sensor data,D,LLMs & NLP
Q41,What is the key characteristic of L2 Regularization (Ridge Regression) regarding the weights in a linear model?,"It drives a subset of weights exactly to zero, performing feature selection.","It drives all weights towards zero, but none exactly to zero (unless they are already zero).","It drives all weights towards zero, but none exactly to zero (unless they are already zero).","It only penalizes the bias term, not the feature weights.",B,Regression & Loss
Q42,"In the context of Polynomial Regression, what problem is most likely to occur if the degree of the polynomial is chosen to be excessively high (e.g., M=10 for a small dataset)?",Underfitting (High Bias),Overfitting (High Variance),Overfitting (High Variance),Vanishing Gradient,B,Regression & Loss
Q43,The Logistic Loss (Cross-Entropy Loss) function is the preferred optimization criterion for which classification model?,Linear Regression,Support Vector Machines,Logistic Regression,K-means Clustering,C,Regression & Loss
Q44,What does the term Precision measure in a binary classification problem?,The fraction of actual positive instances that were correctly identified.,The fraction of correctly classified instances overall.,The fraction of positive predictions that were actually correct.,The fraction of negative instances that were correctly identified.,C,Classification & Metrics
Q45,The Area Under the ROC Curve (AUC-ROC) is a desirable metric because it measures the model's ability to discriminate between positive and negative classes independent of what?,The choice of loss function.,The kernel function used.,The specific classification threshold chosen.,The number of training samples.,C,Classification & Metrics
Q46,A model that has high bias and low variance typically suggests what about its performance?,The model has overfit the training data.,The model is too flexible and complex.,The model is too simple (underfit) and consistently misses the true relationship.,The model is performing optimally across both training and test sets.,C,Bias-Variance
Q47,"If two models achieve the same Accuracy, but Model A has higher Recall and Model B has higher Precision, which model is better for a task where minimizing False Negatives (FN) is the priority (e.g., medical diagnosis)?",Model A (Higher Recall),Model B (Higher Precision),Model A (Higher Recall),A third model using only True Negatives.,A,Classification & Metrics
Q48,"The objective function of a Support Vector Machine (SVM) is a trade-off between maximizing the margin and minimizing the number of misclassification errors, achieved through the use of which specific variables?",Regularization coefficients λ,Slack variables ξi​,Slack variables ξi​,Kernel function parameters γ,B,Regression & Loss
Q49,"A major drawback of the k-Nearest Neighbor (k-NN) algorithm, especially in high-dimensional spaces, is often referred to as the:",Vanishing Gradient problem.,Curse of Dimensionality.,Curse of Dimensionality.,Maximum Margin principle.,B,Non-Parametric
Q50,"In a Decision Tree, the search for the optimal split at any node is performed using a greedy approach. What does ""greedy"" mean in this context?",The tree aims to minimize the total tree depth regardless of impurity.,"The split is chosen only based on maximizing the impurity decrease (e.g., Information Gain) at that specific node.","The split is chosen only based on maximizing the impurity decrease (e.g., Information Gain) at that specific node.",The split is chosen based on optimizing the entire tree's performance simultaneously.,B,Non-Parametric
Q51,What is the process of removing branches from a fully grown Decision Tree to improve its generalization and prevent overfitting called?,Pruning,Boosting,Pruning,Parzen estimation,A,Non-Parametric
Q52,Bagging (Bootstrap Aggregating) for classification involves training multiple base classifiers on bootstrapped subsets of data and combining their final predictions using which method?,Weighted average of probabilities.,Majority voting.,Majority voting.,Sequential correction of errors.,B,Ensemble Methods
Q53,"How do Extra Trees (Extremely Randomized Trees) typically differ from a standard Random Forest, specifically regarding the split-point selection?",Extra Trees only use a single feature for the entire tree.,"Extra Trees build the trees sequentially, not in parallel.","Extra Trees choose the split point randomly within the feature's range, instead of deterministically finding the best impurity-minimizing split.",Extra Trees use boosting instead of bagging.,C,Ensemble Methods
Q54,"For the k-Nearest Neighbor (k-NN) algorithm, selecting a very large value for k (the number of neighbors) typically leads to:",A model with high variance (overfitting).,A very flexible decision boundary.,A smoother decision boundary and high bias (underfitting).,Faster training time.,C,Non-Parametric
Q55,Which statement accurately describes a key advantage of non-parametric methods (like k-NN or Parzen Estimator) over parametric methods (like Linear Regression)?,They make no assumptions about the functional form of the underlying probability distribution.,They are always faster to train on very large datasets.,They make no assumptions about the functional form of the underlying probability distribution.,They always result in a linear decision boundary.,A,Non-Parametric
Q56,"In the Parzen Estimator, what is the primary role of the kernel (or window function)?",To define the specific number of nearest neighbors (k).,To determine the shape and size of the region R around the point x used for density estimation.,To determine the shape and size of the region R around the point x used for density estimation.,To convert the continuous density into a discrete probability mass.,B,Non-Parametric
Q57,"When using the K-means algorithm, what common preprocessing step is necessary before running the algorithm, especially if features have different scales (e.g., height in meters and income in Euros)?",Normalization or Standardization of the features.,Applying a non-linear activation function.,Normalization or Standardization of the features.,Increasing the number of clusters K.,A,Clustering & Preprocessing
Q58,"In the DBSCAN algorithm, a data point is considered a Core Point if it has at least MinPts neighbors within a distance of ϵ. Points that are within ϵ of a Core Point but are not Core Points themselves are called:",Noise points.,Border points.,Border points.,Outlier points.,B,Clustering
Q59,The elbow method is a common technique used to empirically determine an appropriate value for which hyperparameter?,The regularization coefficient λ.,The learning rate η.,The number of clusters K in K-means.,The window size in Parzen estimation.,C,Clustering
Q60,"When performing Principal Component Analysis (PCA), the principal components are chosen such that they are:",Parallel to the original coordinate axes.,Mutually orthogonal (uncorrelated) and ordered by the variance they capture.,Mutually orthogonal (uncorrelated) and ordered by the variance they capture.,Equally important in terms of variance.,B,Feature Learning & PCA
Q61,A feature is considered translation invariant if:,It remains the same when the data matrix is rotated.,It remains the same when a constant vector is added to the input data x.,It remains the same when a constant vector is added to the input data x.,Its magnitude changes linearly with the input data.,B,Feature Learning
Q62,What is the fundamental disadvantage of manually defining features through Feature Engineering compared to Feature Learning methods (like deep learning)?,It often results in a non-linear model.,It requires substantial domain knowledge and is labor-intensive.,It requires substantial domain knowledge and is labor-intensive.,It is computationally more expensive during the training phase.,B,Feature Learning
Q63,"What is the goal of normalization (e.g., Min-Max scaling) in feature pre-processing?",To ensure all features have a Gaussian distribution.,"To transform features to a specific range, often [0,1].","To transform features to a specific range, often [0,1].",To reduce the number of features.,B,Preprocessing
Q64,"In the context of the Kernel Trick, the key function K(xi​,xj​)=ϕ(xi​)Tϕ(xj​) allows the algorithm to implicitly work in a high-dimensional space without ever explicitly computing what?",The squared error loss.,The feature vector ϕ(x).,The feature vector ϕ(x).,The regularization constant.,B,Feature Learning
Q65,Which of the following is an example of a discrete probability distribution?,Gaussian (Normal) Distribution,Student's t-Distribution,Binomial Distribution,Dirichlet Distribution,C,Probability
Q66,Which type of probability distribution is defined over a continuous variable and is characterized by its mean (μ) and variance (σ2)?,Bernoulli Distribution,Poisson Distribution,Gaussian (Normal) Distribution,Uniform Distribution,D,Probability
Q67,"In Bayesian Estimation, the term $P(\theta",D)$ is known as the Posterior distribution. It is proportional to the product of which two components?,Prior P(θ) and Marginal Likelihood P(D).,Likelihood $P(D,\theta)$ and Prior P(θ).,**Likelihood $P(D,\theta)$ and Prior P(θ).**
Q68,"What type of uncertainty is primarily addressed by using a Bayesian model (e.g., Bayesian Neural Network), which places distributions over the model weights?",Aleatoric Uncertainty (data noise),Epistemic Uncertainty (model uncertainty),Epistemic Uncertainty (model uncertainty),Computational Uncertainty,B,Probability & Estimation
Q69,Why is optimization often performed on the log-likelihood instead of the likelihood in MLE?,Log-likelihood is always a positive value.,"It converts the product of probabilities into a sum, which is mathematically easier to differentiate and maximize.","It converts the product of probabilities into a sum, which is mathematically easier to differentiate and maximize.",It changes the optimization problem from maximization to minimization.,B,Probability & Estimation
Q70,The Bernoulli distribution is a special case of which other distribution when the number of trials N=1?,Poisson Distribution,Exponential Distribution,Binomial Distribution,Gaussian Distribution,C,Probability
Q71,"What does it mean for two events, A and B, to be statistically independent?",P(A∩B)=0,$P(A,B) = 0$,P(A∩B)=P(A)P(B),P(A)=P(B),C
Q72,Which classifier makes a decision based on the ratio of the posterior probabilities $P(C_k,"\vec{x})$ for the different classes, often by minimizing the risk?",Support Vector Machine,Decision Tree,Bayesian Classifier (or Bayes Decision Theory),k-Nearest Neighbor,C
Q73,"What is the primary purpose of the activation function (e.g., ReLU, Sigmoid) in a standard neuron of a Neural Network?",To initialize the neuron's weights.,To transform the weighted sum of inputs into an output and introduce non-linearity.,To transform the weighted sum of inputs into an output and introduce non-linearity.,To regulate the learning rate of the network.,B,Deep Learning
Q74,"In a CNN, the weights of a single convolutional filter are shared across the entire input image. What is the main advantage of this Weight Sharing?",It eliminates the need for a non-linear activation function.,"It significantly reduces the total number of parameters, making the model easier to train.","It significantly reduces the total number of parameters, making the model easier to train.",It ensures that the network is translation invariant by default.,B,Deep Learning
Q75,"Which type of layer in a CNN is typically placed after a Convolutional Layer and an Activation function, and is designed to create a down-sampled (coarser) feature map?",Fully Connected Layer,Softmax Layer,Pooling Layer,Recurrent Layer,D,Deep Learning
Q76,The Gated Recurrent Unit (GRU) is a simplified version of the LSTM cell. What is the main simplification it achieves compared to the standard LSTM?,"It uses a single gate (the update gate) instead of the three gates (Input, Forget, Output).",It only uses the Tanh activation function.,"It merges the forget and input gates into a single update gate, and combines the cell state and hidden state.",It only works with short sequences of data.,C,Deep Learning
Q77,"In the multi-armed bandit problem, what is the Regret that the agent aims to minimize?",The number of non-optimal arms chosen.,The accumulated difference between the reward of the optimal arm and the reward of the arm actually chosen.,The accumulated difference between the reward of the optimal arm and the reward of the arm actually chosen.,The variance of the estimated rewards.,B,RL & Bandits
Q78,The ϵ-greedy action selection strategy in Multi-armed Bandits exploits with probability 1−ϵ and does what with probability ϵ?,Choosing the second-best arm.,Choosing a random arm (exploration).,Choosing a random arm (exploration).,Choosing the arm with the lowest known reward.,B,RL & Bandits
Q79,Word Embeddings (like those learned by Word2Vec) are dense vector representations of words that capture what property?,The precise length of the word in characters.,The historical usage frequency of the word in a corpus.,The semantic (meaning) and syntactic (grammatical) relationships between words.,The part-of-speech tag for the word.,C,LLMs & NLP
Q80,A key advantage of the Transformer architecture over traditional RNNs is its ability to process the entire input sequence simultaneously. This is known as:,Sequential computation.,Convolutional processing.,Parallel processing (or lack of recurrence).,The Backpropagation method.,C,LLMs & NLP
Q81,"In the context of a decision boundary, what does a hard margin Support Vector Machine (SVM) require?","That all training points are correctly classified, even if it results in a small margin.",That all training points must lie on or outside the margin boundaries.,That all training points are perfectly separable without any misclassifications within the margin.,That the dual form of the optimization problem is used.,C,SVM & Regression
Q82,"Which measure is a strictly proper scoring rule that can be used to assess the quality of probabilistic predictions (i.e., how close the predicted probability p is to the true outcome y)?",F-score,Accuracy,Brier Score,Mean Absolute Error (MAE),C,Classification Metrics
Q83,What is the primary characteristic that distinguishes L1 Regularization (Lasso Regression) from L2 Regularization?,L1 is faster to compute.,"L1 drives more weights towards, but not exactly to, zero.","L1 can force some weight coefficients exactly to zero, effectively performing automatic feature selection.",L1 works better for non-linear models.,C,Regression & Loss
Q84,"Which term describes a Decision Tree where the splitting process is stopped prematurely, usually based on a threshold for node impurity or a maximum tree depth?",Bagging,Boosting,Pruning,Ensemble learning,A,Non-Parametric
Q85,"In the Parzen Estimator, what happens to the estimated probability density P(x) if the kernel window width is chosen to be very large?","The estimate becomes very sensitive (low bias, high variance).",The density estimate will always be zero.,The estimate becomes very smooth and prone to underfitting (high bias).,The estimate requires the calculation of k-nearest neighbors.,C,Non-Parametric
Q86,"In k-Nearest Neighbor (k-NN) classification, the decision boundary is inherently non-linear and formed by what shapes?",A set of linear hyperplanes determined by support vectors.,A single polynomial function of a fixed degree.,Voronoi tessellation of the feature space.,A set of orthogonal principal components.,C,Non-Parametric
Q87,The Gaussian kernel (Radial Basis Function Kernel) is known for mapping data into a potentially infinite-dimensional space and is controlled by which hyperparameter?,The degree of the polynomial d.,The number of support vectors k.,The bandwidth or gamma parameter γ (or σ2).,The regularization term C.,C,Feature Learning
Q88,What is the main advantage of calculating Term Frequency-Inverse Document Frequency (TF-IDF) over simple Term Frequency (TF) for text features?,TF-IDF is easier to compute.,TF-IDF is a categorical feature.,"TF-IDF gives higher weight to words that are rare across the entire document set, making them more informative.",TF-IDF works only for image data.,C,Text Features
Q89,What is the process of applying an image filter (like a smoothing filter) by sliding it across the input image and computing the element-wise product and sum called?,Pooling,Batch Normalization,Convolution,Max-pooling,C,Image Features
Q90,"In the Clustering algorithm K-means, which distance metric is almost universally used as the default measure of similarity between points?",Manhattan Distance (L1 norm),Mahalanobis Distance,Euclidean Distance (L2 norm),Hinge Loss,C,Clustering
Q91,"If a K-means algorithm converges to a set of cluster centers, what has the algorithm successfully found?",The globally optimal minimum of the WCSS objective function.,A linearly separable decision boundary.,A local minimum of the Within-Cluster Sum of Squares (WCSS).,The correct number of clusters K.,C,Clustering
Q92,"For DBSCAN, a point that is reachable from a Core Point but is not a Core Point itself is called a Border Point. A point that is not a Core Point and not reachable from any Core Point is called what?",An ϵ-neighbor,A Seed Point,A Noise Point (or Outlier),A Centroid,C,Clustering
Q93,The Bernoulli Distribution describes the probability of an event with only two outcomes (success/failure). What is the single parameter that defines this distribution?,The number of trials N.,The variance σ2.,The probability of success p.,The mean μ.,C,Probability
Q94,What is the definition of the Expected Value E[X] of a random variable X?,The variance of the distribution.,The most likely outcome (mode).,"The weighted average of all possible values, where the weights are their respective probabilities.",The value that separates the distribution into two equal halves (median).,C,Probability
Q95,"In the context of probability theory, what is the key difference between Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) estimation?","MLE minimizes the error, while MAP maximizes the error.","MLE is non-parametric, while MAP is parametric.","MAP incorporates a prior distribution over the parameters, while MLE only considers the likelihood of the data.",MAP requires the use of the L2 regularization norm.,C,Probability & Estimation
Q96,What is the primary cause of Epistemic Uncertainty in machine learning?,Inherent randomness and noise in the data generating process.,Computational errors during the gradient descent.,"Lack of data or knowledge (e.g., in regions far from the training data).",The choice of activation function.,C,Probability & Estimation
Q97,"The Action-Value Function Q(s,a) in Reinforcement Learning (RL) is defined as:",The probability of taking action a in state s.,The expected immediate reward upon taking action a in state s.,The expected cumulative future reward starting from state s and taking action a.,The difference between the optimal policy and the current policy.,C,RL & Bandits
Q98,"In the Multi-armed Bandit problem, which action selection strategy is considered a pure exploitation strategy?",ϵ-greedy,Softmax action selection,Greedy (always choosing the arm with the highest estimated mean reward).,Upper Confidence Bound (UCB),C,RL & Bandits
Q99,"The bonus term in the Upper Confidence Bound (UCB) action selection algorithm is often based on Na​(t)lnt​​. Why does the bonus term have an inverse dependence on Na​(t), the number of times arm a has been pulled?",To prioritize arms with high estimated rewards.,To reduce the total computational complexity.,To encourage exploration of arms that have been sampled less frequently (to reduce uncertainty).,To increase the overall regret.,C,RL & Bandits
Q100,What feature distinguishes a Contextual Bandit from a non-contextual (Multi-armed) Bandit?,Delayed rewards instead of immediate rewards.,The ability to choose continuous actions.,The action selection is conditioned on an observable state or feature vector (context).,The number of arms changes over time.,C,RL & Bandits
Q101,"The simplest form of a neural network neuron computes a weighted sum of its inputs, then passes this sum through which component?",The Backpropagation algorithm,The Pooling Layer,An activation function.,A convolutional kernel.,C,Deep Learning
Q102,"Which non-linear activation function is commonly used in the final layer of a Neural Network for a multi-class classification problem, as it outputs a probability distribution over the classes?",ReLU,Sigmoid,Softmax,Tanh,C,Deep Learning
Q103,"When optimizing a Deep Learning model, the learning rate (η) is a hyperparameter of which specific algorithm?",The Forward Pass,The Activation Function,The Gradient Descent (or optimization) algorithm.,The Backpropagation algorithm,C,Deep Learning
Q104,"In a Convolutional Neural Network (CNN), the stride parameter in the convolutional layer controls what?",The number of feature maps generated.,The size of the kernel filter.,The step size by which the convolutional filter slides across the input.,The amount of padding added to the input boundaries.,C,Deep Learning
Q105,The Max Pooling operation in a CNN extracts which value from a small region (window) of the input feature map?,The average of the values in the region.,The sum of the values in the region.,The single largest value in the region.,The variance of the values in the region.,C,Deep Learning
Q106,What is the main characteristic of the ReLU (Rectified Linear Unit) activation function?,It outputs a value between 0 and 1.,It uses a trigonometric function.,"It outputs the input if it is positive, and 0 otherwise.",It prevents the gradient from exploding.,C,Deep Learning
Q107,The vanishing gradient problem in training standard RNNs is primarily caused by what?,The non-linear nature of the Softmax function.,The use of convolutional layers.,"Repeated multiplication of gradients through many time steps, leading to exponential decay.",An overly small batch size.,C,Deep Learning
Q108,Long Short-Term Memory (LSTM) networks control the flow of information through the cell state using which specific components?,Convolutional kernels,Pooling layers,"Gates (Input, Forget, Output).",The attention mechanism.,C,Deep Learning
Q109,The Bag-of-Words (BoW) model for text feature extraction typically results in a vector representation that:,Is dense and semantic.,Captures the sequential order of the words.,"Is sparse and only counts word frequencies, losing word order.",Is dependent on the L1 regularization norm.,C,LLMs & NLP
Q110,"In Natural Language Processing (NLP), a semantic model is primarily focused on capturing what aspect of language?",The grammatical correctness of sentences.,The frequency of punctuation marks.,The meaning and context of words and phrases.,The historical evolution of the language.,C,LLMs & NLP
Q111,The Transformer architecture (used in LLMs) completely replaces which component found in traditional RNNs?,The Softmax output layer.,The fully connected feed-forward layers.,The recurrent connections (LSTMs/GRUs).,The loss function.,C,LLMs & NLP
Q112,"In the Attention Mechanism of a Transformer, which three learned vectors are calculated from the input and used to compute the attention weights?","Input, Output, and Hidden vectors.","Weights, Biases, and Activations.","Query, Key, and Value vectors.","Feature, Label, and Loss vectors.",C,LLMs & NLP
Q113,A key application of unsupervised learning mentioned in the course is using clustering for what purpose?,Predicting future stock prices.,Maximizing the cumulative reward of an agent.,Finding groups of similar data points (patterns) in unlabeled data.,Separating linearly separable data points.,C,Introduction & Basics
Q114,The total data matrix D in supervised learning is composed of two main components: the feature vectors xi​ and what?,The model parameters w.,The expected reward R.,The target labels/values yi​.,The regularization term λ.,C,Introduction & Basics
Q115,"In the context of the Least Squares Estimation for Linear Regression, what does the term ""Least Squares"" specifically refer to?",Minimizing the L1 norm of the weight vector.,Maximizing the likelihood of the parameters.,Minimizing the sum of the squared differences between the predicted and actual values (Quadratic Loss).,Minimizing the maximum classification error.,C,Regression
Q116,Bootstrap Aggregating (Bagging) is primarily effective at reducing variance if the individual models used in the ensemble are:,Highly accurate and complex.,"All the same type of model (e.g., all linear models).",Unstable (small changes in training data lead to large changes in the model) and diverse.,Trained sequentially rather than in parallel.,C,Ensemble Methods
Q117,Which scenario is best suited for a Linear Kernel in an SVM?,The data points are non-linearly separable and heavily overlapping.,The data requires mapping to an infinite-dimensional space.,"The data is believed to be linearly separable, or the problem has a very large number of features.",The goal is to maximize the posterior probability.,C,Feature Learning
Q118,What is the main characteristic of a parametric method in machine learning?,It requires an infinite amount of training data.,It uses only non-linear decision boundaries.,"It assumes a fixed functional form for the model (e.g., a linear equation) that is fully defined by a finite number of parameters.",It only works for regression tasks.,C,Non-Parametric
Q119,The Softmax function in the final layer of a neural network is commonly combined with which loss function for multi-class classification?,Hinge Loss,Quadratic Loss,Cross-Entropy Loss (or Logistic Loss).,Mean Squared Error.,C,Deep Learning
Q120,What is a fundamental challenge in all forms of Reinforcement Learning (RL)?,The inability to use neural networks.,The requirement of a perfectly labeled training set.,The long-term credit assignment problem (determining which past action caused a current reward).,The necessity of a strictly linear policy.,C,RL & Bandits